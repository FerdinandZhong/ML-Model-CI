{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deploy Object Detection Model Use ModelCI\n",
    "\n",
    "MMDetction is a well-known open source object detection toolbox based on PyTorch. You can refer to <https://arxiv.org/abs/1906.07155> for more details.\n",
    "\n",
    "By walking through this tutorial, you will be able to:\n",
    "\n",
    "- Load pretained MMDetction model\n",
    "- Convert MMDetction model into ONNX format \n",
    "- Register and retrieve models by ModelHub\n",
    "\n",
    " ## 1. Prequisities\n",
    " \n",
    " ### 1.1 Installation of MMDetction\n",
    " \n",
    " Firstly you have to install MMDetction according to official instructions : <https://mmdetection.readthedocs.io/en/latest/get_started.html#installation> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Obtaining file:///home/sherry/project/github/ML-Model-CI/example/notebook/mmdetection\n",
      "Requirement already satisfied: matplotlib in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (3.3.3)\n",
      "Requirement already satisfied: mmpycocotools in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (12.0.3)\n",
      "Requirement already satisfied: numpy in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (1.19.2)\n",
      "Requirement already satisfied: six in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (1.15.0)\n",
      "Requirement already satisfied: terminaltables in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (1.3.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmpycocotools->mmdet==2.7.0) (51.0.0.post20201207)\n",
      "Requirement already satisfied: cython>=0.27.3 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmpycocotools->mmdet==2.7.0) (0.29.21)\n",
      "Installing collected packages: mmdet\n",
      "  Attempting uninstall: mmdet\n",
      "    Found existing installation: mmdet 2.7.0\n",
      "    Uninstalling mmdet-2.7.0:\n",
      "      Successfully uninstalled mmdet-2.7.0\n",
      "  Running setup.py develop for mmdet\n",
      "Successfully installed mmdet\n"
     ]
    }
   ],
   "source": [
    "!pip install https://download.openmmlab.com/mmcv/dist/latest/torch1.7.0/cu102/mmcv_full-latest%2Btorch1.7.0%2Bcu102-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!git clone https://github.com/open-mmlab/mmdetection.git\n",
    "!cd mmdetection && pip install -q -r requirements/build.txt && pip install -q -v -e ."
   ]
  },
  {
   "source": [
    "### 1.2 Start ModelCI Service\n",
    "Then we can start our ModelCI service, you should at least set mongodb password before starting. You can refer to [last notebook](https://github.com/cap-ntu/ML-Model-CI/blob/master/example/notebook/image_classification_model_deployment.ipynb) for more details."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: MONGO_PASSWORD=modelci@2020\n",
      "2020-12-24 09:56:20,119 - ml-modelci Docker Container Manager - INFO - Container name=mongo-99022 stared\n",
      "2020-12-24 09:56:21,831 - ml-modelci Docker Container Manager - INFO - Container name=cadvisor-75216 started.\n",
      "2020-12-24 09:56:26,296 - ml-modelci Docker Container Manager - INFO - Container name=dcgm-exporter-29627 started.\n",
      "2020-12-24 09:56:28,282 - ml-modelci Docker Container Manager - INFO - gpu-metrics-exporter-28682 stared\n",
      "2020-12-24 09:56:28,571 - modelci backend - INFO - Uvicorn server listening on 8000\n"
     ]
    }
   ],
   "source": [
    "%env MONGO_PASSWORD=modelci@2020\n",
    "!conda activate modelci && modelci start"
   ]
  },
  {
   "source": [
    "## 2. Build MMdetection Model\n",
    "### 2.1 Imports\n",
    "We should import the following functions:\n",
    "- preprocess_example_input: for generating tensor and meta info from example image file\n",
    "- build_model_from_cfg: for building model form config file and checkpoint file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.core import preprocess_example_input, build_model_from_cfg"
   ]
  },
  {
   "source": [
    "### 2.2 Model Config\n",
    "\n",
    "We should either use a dict or config file for configuration of MMDetection model, to make things simple, we use a config file provided by MMDetection.\n",
    "\n",
    "Notice: \n",
    "\n",
    "- You may need to manually download pretrained model checkpoints from [MMDetection models zoo](https://github.com/open-mmlab/mmdetection/blob/master/docs/model_zoo.md).\n",
    "- Only a few MMdet models are able to converted into ONNX format, you can refer to [documentation](https://mmdetection.readthedocs.io/en/latest/tutorials/pytorch2onnx.html#list-of-supported-models-exportable-to-onnx) for more detail."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'mmdetection/configs/retinanet/retinanet_r50_fpn_1x_coco.py'\n",
    "checkpoint_file = 'retinanet_r50_fpn_1x_coco_20200130-c2398f9e.pth'"
   ]
  },
  {
   "source": [
    "### 2.3 Build Model\n",
    "Then we can build our MMdetection model based on the configuration above and the checkpoint file we already download."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_cfg(config_file, checkpoint_file)"
   ]
  },
  {
   "source": [
    "Before conversion, we need to modify forward function to provide the necessary **kwargs parameters such as img_metas.\n",
    "\n",
    "In order to obtain valid bbox data during the onnx tracing process, we also need to use a tensor generated from image file as model input instead of random tensors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = {\n",
    "    'input_shape': (1,3,224,224),\n",
    "    'input_path': 'mmdetection/demo/demo.jpg',\n",
    "    'normalize_cfg': {\n",
    "        'mean': (123.675, 116.28, 103.53),\n",
    "        'std': (58.395, 57.12, 57.375)\n",
    "        }\n",
    "}\n",
    "one_img, one_meta = preprocess_example_input(input_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "one_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "model.forward = partial(model.forward, img_metas=[[one_meta]], return_loss=False)"
   ]
  },
  {
   "source": [
    "## 3. Register Model\n",
    "We can convert the pytorch model above into optimized formats, such as ONNX through modelci\n",
    "\n",
    "### 3.1 Imports\n",
    "- modelci.hub.manager: for registering model into ModelHub\n",
    "- modelci.types.bo: for constructing model inputs paramenters\n",
    "- modelci.types.trtis_objects: for specifying model input shape format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.manager import register_model\n",
    "from modelci.types.bo import IOShape, Framework, Task, Engine, Metric, ModelVersion\n",
    "from modelci.types.trtis_objects import ModelInputFormat"
   ]
  },
  {
   "source": [
    "### 3.2 Sepcify Input and Output\n",
    "\n",
    "Here are some parameters need to be specified before model conversion.\n",
    "- inputs: The model inputs info\n",
    "- outputs: The model outputs info\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [IOShape([-1, 3, 204, 204], dtype=float, name='IMAGE', format=ModelInputFormat.FORMAT_NCHW)]\n",
    "outputs = [\n",
    "    IOShape([-1, 100, 5], dtype=float, name='BBOX'),\n",
    "    IOShape([-1, 100], dtype=float, name='SCORE')\n",
    "    ]"
   ]
  },
  {
   "source": [
    "### 3.3 Register\n",
    "\n",
    "In this step, the inputs and outputs variable generated before are reused. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-01-13 21:54:15,831 - converter - WARNING - This model is not supported as torchscript format\n",
      "2021-01-13 21:54:23,234 - converter - INFO - ONNX format converted successfully\n"
     ]
    }
   ],
   "source": [
    "register_model(\n",
    "    model,\n",
    "    dataset='COCO',\n",
    "    task=Task.OBJECT_DETECTION,\n",
    "    metric={Metric.MAP: 0.365},\n",
    "    outputs=outputs,\n",
    "    inputs=inputs,\n",
    "    architecture='RetinaNet',\n",
    "    framework=Framework.PYTORCH,\n",
    "    version=ModelVersion('1'),\n",
    "    model_input=[one_img],\n",
    "    profile=False\n",
    ")"
   ]
  },
  {
   "source": [
    "As we could see, MLModelCI support auto conversion of PyTorch models into both torchscript and ONNX format, as a result.\n",
    "\n",
    "However, this model cannot be transformed into torchscript format, but supportive of ONNX format conversion, there could be serveral factors contributing to model conversion failture such as the model structure and code format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4. Retrieve Model\n",
    "\n",
    "The following steps will retrieve the model we just registered."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.manager import retrieve_model\n",
    "retrieved_models = retrieve_model(\n",
    "        architecture_name = 'RetinaNet',\n",
    "        framework = Framework.PYTORCH,\n",
    "        version=ModelVersion('1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<modelci.types.bo.model_bo.ModelBO at 0x7fb5f8b3ec90>,\n",
       " <modelci.types.bo.model_bo.ModelBO at 0x7fb61402d690>]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "retrieved_models"
   ]
  },
  {
   "source": [
    "It's no wonder we get two model objects here cause there is an addition ONNX format model created automatically during previous registering process."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_id': '5ffefb92681bb7cb565e3465',\n",
       " 'name': 'RetinaNet',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.ONNX: 3>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7fb614070450>,\n",
       " 'dataset': 'COCO',\n",
       " 'metric': {<Metric.MAP: 1>: 0.365},\n",
       " 'task': <Task.OBJECT_DETECTION: 1>,\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7fb614070590>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7fb614070610>,\n",
       "  <modelci.types.bo.model_objects.IOShape at 0x7fb5f8b3ead0>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7fb5f8b3ed50>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.UNKNOWN: 0>,\n",
       " 'creator': 'shanshan',\n",
       " 'create_time': datetime.datetime(2021, 1, 13, 21, 54, 5, 916000)}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "retrieved_models[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_id': '5ffefb91681bb7cb565e321b',\n",
       " 'name': 'RetinaNet',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.PYT: 6>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7fb5d231d850>,\n",
       " 'dataset': 'COCO',\n",
       " 'metric': {<Metric.MAP: 1>: 0.365},\n",
       " 'task': <Task.OBJECT_DETECTION: 1>,\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7fb61408d350>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7fb61408d950>,\n",
       "  <modelci.types.bo.model_objects.IOShape at 0x7fb61402d950>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7fb5f8b78f10>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.UNKNOWN: 0>,\n",
       " 'creator': 'shanshan',\n",
       " 'create_time': datetime.datetime(2021, 1, 13, 21, 54, 5, 916000)}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "retrieved_models[1].__dict__"
   ]
  }
 ]
}