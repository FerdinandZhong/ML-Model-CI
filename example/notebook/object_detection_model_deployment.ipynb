{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "8c15c9332713eed1a81c21327630eb7ae7e3c87e5d02abc8e381d87f5b2a5fde"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deploy Object Detection Model Use ModelCI\n",
    "\n",
    "MMDetction is a well-known open source object detection toolbox based on PyTorch. You can refer to <https://arxiv.org/abs/1906.07155> for more details.\n",
    "\n",
    "At the end of this tutorial, you will be able to:\n",
    "\n",
    "- Load pretained MMDetction model\n",
    "- Convert MMDetction model into ONNX format \n",
    "- Register and retrieve models by ModelHub\n",
    "\n",
    " ## 1. Prequisities\n",
    " \n",
    " ### 1.1 Installation of MMDetction\n",
    " \n",
    " Firstly you have to install MMDetction according to official instructions : <https://mmdetection.readthedocs.io/en/latest/get_started.html#installation> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Obtaining file:///home/sherry/project/github/ML-Model-CI/example/notebook/mmdetection\n",
      "Requirement already satisfied: matplotlib in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (3.3.3)\n",
      "Requirement already satisfied: mmpycocotools in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (12.0.3)\n",
      "Requirement already satisfied: numpy in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (1.19.2)\n",
      "Requirement already satisfied: six in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (1.15.0)\n",
      "Requirement already satisfied: terminaltables in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmdet==2.7.0) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from matplotlib->mmdet==2.7.0) (1.3.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmpycocotools->mmdet==2.7.0) (51.0.0.post20201207)\n",
      "Requirement already satisfied: cython>=0.27.3 in /home/sherry/project/miniconda3/envs/test/lib/python3.7/site-packages (from mmpycocotools->mmdet==2.7.0) (0.29.21)\n",
      "Installing collected packages: mmdet\n",
      "  Attempting uninstall: mmdet\n",
      "    Found existing installation: mmdet 2.7.0\n",
      "    Uninstalling mmdet-2.7.0:\n",
      "      Successfully uninstalled mmdet-2.7.0\n",
      "  Running setup.py develop for mmdet\n",
      "Successfully installed mmdet\n"
     ]
    }
   ],
   "source": [
    "!pip install https://download.openmmlab.com/mmcv/dist/latest/torch1.7.0/cu102/mmcv_full-latest%2Btorch1.7.0%2Bcu102-cp37-cp37m-manylinux1_x86_64.whldownload.openmmlab.com/mmcv/dist/index.html\n",
    "!git clone https://github.com/open-mmlab/mmdetection.git\n",
    "!cd mmdetection && pip install -q -r requirements/build.txt && pip install -q -v -e ."
   ]
  },
  {
   "source": [
    "### 1.2 Start ModelCI Service\n",
    "Then we can start our ModelCI service, you should at least set mongodb password before starting. You can refer to [last notebook](https://github.com/cap-ntu/ML-Model-CI/blob/master/example/notebook/image_classification_model_deployment.ipynb) for more details."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: MONGO_PASSWORD=modelci@2020\n",
      "2020-12-24 09:56:20,119 - ml-modelci Docker Container Manager - INFO - Container name=mongo-99022 stared\n",
      "2020-12-24 09:56:21,831 - ml-modelci Docker Container Manager - INFO - Container name=cadvisor-75216 started.\n",
      "2020-12-24 09:56:26,296 - ml-modelci Docker Container Manager - INFO - Container name=dcgm-exporter-29627 started.\n",
      "2020-12-24 09:56:28,282 - ml-modelci Docker Container Manager - INFO - gpu-metrics-exporter-28682 stared\n",
      "2020-12-24 09:56:28,571 - modelci backend - INFO - Uvicorn server listening on 8000\n"
     ]
    }
   ],
   "source": [
    "%env MONGO_PASSWORD=modelci@2020\n",
    "!conda activate modelci && modelci start"
   ]
  },
  {
   "source": [
    "## 2. Build MMdetection Model\n",
    "### 2.1 Imports\n",
    "We should import the following functions:\n",
    "- preprocess_example_input: for generating tensor and meta info from example image file\n",
    "- build_model_from_cfg: for building model form config file and checkpoint file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.core import preprocess_example_input, build_model_from_cfg"
   ]
  },
  {
   "source": [
    "### 2.2 Model Config\n",
    "\n",
    "We should either use a dict or config file for configuration of MMDetection model, to make things simple, we use a config file provided by MMDetection.\n",
    "\n",
    "Notice: \n",
    "\n",
    "- You may need to manually download pretrained model checkpoints from [MMDetection models zoo](https://github.com/open-mmlab/mmdetection/blob/master/docs/model_zoo.md).\n",
    "- Only a few MMdet models are able to converted into ONNX format, you can refer to [documentation](https://mmdetection.readthedocs.io/en/latest/tutorials/pytorch2onnx.html#list-of-supported-models-exportable-to-onnx) for more detail."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'mmdetection/configs/retinanet/retinanet_r50_fpn_1x_coco.py'\n",
    "checkpoint_file = 'mmdetection/retinanet_r50_fpn_1x_coco_20200130-c2398f9e.pth'"
   ]
  },
  {
   "source": [
    "### 2.3 Build Model\n",
    "Then we can build our MMdetection model based on the configuration above and the checkpoint file we already download."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_cfg(config_file, checkpoint_file)"
   ]
  },
  {
   "source": [
    "Before conversion, we need to modify forward function to provide the necessary **kwargs parameters such as img_metas.\n",
    "\n",
    "In order to obtain valid bbox data during the onnx tracing process, we also need to use a tensor generated from image file as model input instead of random tensors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_config = {\n",
    "    'input_shape': (1,3,224,224),\n",
    "    'input_path': 'mmdetection/demo/demo.jpg',\n",
    "    'normalize_cfg': {\n",
    "        'mean': (123.675, 116.28, 103.53),\n",
    "        'std': (58.395, 57.12, 57.375)\n",
    "        }\n",
    "}\n",
    "one_img, one_meta = preprocess_example_input(input_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "one_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "model.forward = partial(model.forward, img_metas=[[one_meta]], return_loss=False)"
   ]
  },
  {
   "source": [
    "## 3. Convert Model\n",
    "We can convert the pytorch model above into optimized formats, such as ONNX through Modelci\n",
    "\n",
    "### 3.1 Imports\n",
    "- modelci.hub.converter: for converting torch model into ONNX model\n",
    "- modelci.types.bo: for constructing model inputs paramenters\n",
    "- modelci.hub.utils: for getting generated model's save path\n",
    "- modelci.types.trtis_objects: for specifying model input shape format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.converter import ONNXConverter\n",
    "from modelci.types.bo import IOShape, Framework, Task, Engine, Metric, ModelVersion\n",
    "from modelci.hub.utils import generate_path\n",
    "from modelci.types.trtis_objects import ModelInputFormat"
   ]
  },
  {
   "source": [
    "### 3.2 Revelant Parameters\n",
    "\n",
    "Here are some parameters need to be specified before model conversion.\n",
    "- inputs: The model inputs info\n",
    "- outputs: The model outputs info\n",
    "- onnx_save_path: The path for generated onnx model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [IOShape([-1, 3, 204, 204], dtype=float, name='IMAGE', format=ModelInputFormat.FORMAT_NCHW)]\n",
    "outputs = [\n",
    "    IOShape([-1, 100, 5], dtype=float, name='BBOX'),\n",
    "    IOShape([-1, 100], dtype=float, name='SCORE')\n",
    "    ]\n",
    "onnx_save_path = generate_path(\n",
    "    model_name='RetinaNet', \n",
    "    framework=Framework.PYTORCH,\n",
    "    task=Task.OBJECT_DETECTION,\n",
    "    engine=Engine.ONNX,\n",
    "    version=1\n",
    ")"
   ]
  },
  {
   "source": [
    "### 3.3 Convert\n",
    "\n",
    "In this process, the input tensor we generated above is used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-23 22:49:27,555 - converter - INFO - Begin Simplify ONNX Model ...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "ONNXConverter.from_torch_module(\n",
    "    model, \n",
    "    onnx_save_path, \n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    model_input=[one_img],\n",
    "    opset=11\n",
    ")"
   ]
  },
  {
   "source": [
    "## 3. Register Model\n",
    "\n",
    "### 3.1 Imports\n",
    "\n",
    "- modelci.hub.manager: for registering model into ModelHub\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.manager import register_model"
   ]
  },
  {
   "source": [
    "### 3.2 Register\n",
    "In this step, the inputs and outputs variable generated before are reused. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model(\n",
    "    str(onnx_save_path)+'.onnx',\n",
    "    dataset='COCO',\n",
    "    task=Task.OBJECT_DETECTION,\n",
    "    metric={Metric.MAP: 0.365},\n",
    "    outputs=outputs,\n",
    "    inputs=inputs,\n",
    "    model_input=[one_img],\n",
    "    engine=Engine.ONNX,\n",
    "    architecture='RetinaNet',\n",
    "    framework=Framework.PYTORCH,\n",
    "    version=ModelVersion('1'),\n",
    "    convert=False\n",
    ")"
   ]
  },
  {
   "source": [
    "## 5. Retrieve Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.manager import retrieve_model\n",
    "retrieved_models = retrieve_model(\n",
    "        architecture_name = 'RetinaNet',\n",
    "        framework = Framework.PYTORCH,\n",
    "        version=ModelVersion('1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<modelci.types.bo.model_bo.ModelBO at 0x7fe75232c490>]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "retrieved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_id': '5fe3f5a4f19c77fa0d4ffde0',\n",
       " 'name': 'RetinaNet',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.ONNX: 3>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7fe752355710>,\n",
       " 'dataset': 'COCO',\n",
       " 'metric': {<Metric.MAP: 1>: 0.365},\n",
       " 'task': <Task.OBJECT_DETECTION: 1>,\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7fe752353890>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7fe7502ccb10>,\n",
       "  <modelci.types.bo.model_objects.IOShape at 0x7fe75232c590>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7fe75239ac90>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.RUNNING: 2>,\n",
       " 'creator': 'sherry',\n",
       " 'create_time': datetime.datetime(2020, 12, 24, 9, 57, 27, 842000)}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "retrieved_models[0].__dict__"
   ]
  }
 ]
}