{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# A getting started tutorial of ModelCI installation, Register and convert Model\n",
    "\n",
    "This is a getting started tutorial for those who are new to ML-ModelCI, by the end of this tutorial, you will be able to: \n",
    "\n",
    "- Setting up python environment required by ML-ModelCI.\n",
    "- Start and stop ModelCI service.\n",
    "- Master basic usages of ML-ModelCI, such as model loading, registering,retrieving and converting.\n",
    "- Have a basic understanding of machine learning model lifecycle.\n",
    "\n",
    "## 1. Installation\n",
    "\n",
    "Here are some prequisities before installation\n",
    "\n",
    "- Python version: 3.7\n",
    "- Docker service installed and started\n",
    "- Manually install [TensorRT](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html) if your linux distribution is not Ubuntu\n",
    "\n",
    "Firstly, we should install dependencies specified in `requirements.txt`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "source": [
    "Then we can install the ModelCI python package based on <https://github.com/cap-ntu/ML-Model-CI#using-pip>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/cap-ntu/ML-Model-CI.git@master --use-feature=2020-resolver"
   ]
  },
  {
   "source": [
    "## 2. Start the ModelCI Service\n",
    "\n",
    "Firstly, we should set some environmemnt variables, especially mongodb related variables, just make sure the port you specified is not occupied."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: MONGO_HOST=localhost\nenv: MONGO_PORT=27017\nenv: MONGO_USERNAME=modelci\nenv: MONGO_PASSWORD=modelci@2020\nenv: MONGO_DB=modelci\nenv: MONGO_AUTH_SOURCE=modelci\nenv: BACKEND_CORS_ORIGINS=\"http://localhost,http://localhost:3000,http://localhost:8080,https://localhost:3000,https://localhost:8080\"\nenv: PROJECT_NAME=modelci\nenv: SECRET_KEY=2a6c03b9ca06cd8fc3cf506f0ba924cb735f15918d54758426fd7282366a5e19\n"
     ]
    }
   ],
   "source": [
    "# set environment variables \n",
    "%env MONGO_HOST=localhost\n",
    "%env MONGO_PORT=27017\n",
    "%env MONGO_USERNAME=modelci\n",
    "%env MONGO_PASSWORD=modelci@2020\n",
    "%env MONGO_DB=modelci\n",
    "%env MONGO_AUTH_SOURCE=modelci\n",
    "%env BACKEND_CORS_ORIGINS=\"http://localhost,http://localhost:3000,http://localhost:8080,https://localhost:3000,https://localhost:8080\"\n",
    "%env PROJECT_NAME=modelci\n",
    "%env SECRET_KEY=2a6c03b9ca06cd8fc3cf506f0ba924cb735f15918d54758426fd7282366a5e19"
   ]
  },
  {
   "source": [
    "Then start the modelci service by following command:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-02 10:32:46.805488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-02 10:32:53,276 - ml-modelci Docker Container Manager - INFO - Container name=mongo-76821 stared\n",
      "2020-12-02 10:32:54,671 - ml-modelci Docker Container Manager - INFO - Container name=cadvisor-6052 started.\n",
      "2020-12-02 10:32:57,019 - ml-modelci Docker Container Manager - INFO - Container name=dcgm-exporter-91064 started.\n",
      "2020-12-02 10:32:58,066 - ml-modelci Docker Container Manager - INFO - gpu-metrics-exporter-52271 stared\n",
      "2020-12-02 10:32:58,289 - modelci backend - INFO - Uvicorn server listening on 8000\n"
     ]
    }
   ],
   "source": [
    "!modelci start"
   ]
  },
  {
   "source": [
    "## 2. Register ResNet50 Model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Firstly, we load pre-trained resnet50 model from torchvision, you can refer to <https://pytorch.org/docs/stable/torchvision/models.html> for more examples of pretrained models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load resnet50 model from torchvision\n",
    "from torchvision import models\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "source": [
    "Then we register this model into ModelHub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-02 10:33:14,883 - converter - INFO - Use cached model\n",
      "2020-12-02 10:33:14,884 - converter - INFO - Use cached model\n"
     ]
    }
   ],
   "source": [
    "from modelci.hub.manager import register_model\n",
    "from modelci.types.bo import Framework, IOShape, ModelVersion,Engine\n",
    "from modelci.types.trtis_objects import ModelInputFormat\n",
    "# set model input and output formats\n",
    "inputs = [IOShape([-1, 3, 224, 224], dtype=float, name='INPUT__0', format=ModelInputFormat.FORMAT_NCHW)]\n",
    "outputs = [IOShape([-1, 1000], dtype=float, name='probs')]\n",
    "# register the model\n",
    "register_model(\n",
    "    model,\n",
    "    dataset='imagenet',\n",
    "    acc=0.76,\n",
    "    task='image classification',\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    architecture='ResNet50',\n",
    "    framework=Framework.PYTORCH,\n",
    "    version=ModelVersion('2')\n",
    ")"
   ]
  },
  {
   "source": [
    "## 3. Retrieve Models\n",
    "By default, Converter will automatically convert registered models into optimized formats,PyTorch model can be converted to TorchScipt and ONNX formats, so we can retrieve two models from ModelHub."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for model\n",
    "from modelci.hub.manager import retrieve_model\n",
    "retrieved_models = retrieve_model(\n",
    "        architecture_name = 'ResNet50',\n",
    "        framework = Framework.PYTORCH,\n",
    "        version=ModelVersion('2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<modelci.types.bo.model_bo.ModelBO at 0x7f442046d050>,\n",
       " <modelci.types.bo.model_bo.ModelBO at 0x7f44e8c483d0>]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "retrieved_models"
   ]
  },
  {
   "source": [
    "We can compare detatiled information of these two models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_id': '5fc6fcedf2ede8193ad7095e',\n",
       " 'name': 'ResNet50',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.TORCHSCRIPT: 2>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7f442046d2d0>,\n",
       " 'dataset': 'imagenet',\n",
       " 'acc': 0.76,\n",
       " 'task': 'image classification',\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7f442046d710>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7f442046d110>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7f442046d610>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.RUNNING: 2>,\n",
       " 'creator': 'sherry',\n",
       " 'create_time': datetime.datetime(2020, 12, 2, 10, 33, 13, 880000)}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "retrieved_models[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_id': '5fc6fceff2ede8193ad70ae8',\n",
       " 'name': 'ResNet50',\n",
       " 'framework': <Framework.PYTORCH: 1>,\n",
       " 'engine': <Engine.ONNX: 3>,\n",
       " 'version': <modelci.types.bo.model_objects.ModelVersion at 0x7f4423080210>,\n",
       " 'dataset': 'imagenet',\n",
       " 'acc': 0.76,\n",
       " 'task': 'image classification',\n",
       " 'inputs': [<modelci.types.bo.model_objects.IOShape at 0x7f44fbfa24d0>],\n",
       " 'outputs': [<modelci.types.bo.model_objects.IOShape at 0x7f44e95e6490>],\n",
       " 'weight': <modelci.types.bo.model_objects.Weight at 0x7f44e8d56710>,\n",
       " 'profile_result': None,\n",
       " 'status': <Status.UNKNOWN: 0>,\n",
       " 'creator': 'sherry',\n",
       " 'create_time': datetime.datetime(2020, 12, 2, 10, 33, 13, 880000)}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "retrieved_models[1].__dict__"
   ]
  },
  {
   "source": [
    "## 4. Convert Models\n",
    "We can convert models mannually. \n",
    "\n",
    "You can refer to <https://github.com/cap-ntu/ML-Model-CI/blob/master/docs/tutorial/convert.md> for more details.\n",
    "\n",
    "In the following example, we will convert ONNX model into TensorRT format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelci.hub.converter import TRTConverter\n",
    "from modelci.hub.utils import generate_path\n",
    "from modelci.types.bo import IOShape\n",
    "\n",
    "# set model input and output formats\n",
    "inputs = [IOShape([-1, 3, 224, 224], dtype=float, name='INPUT__0', format=ModelInputFormat.FORMAT_NCHW)]\n",
    "outputs = [IOShape([-1, 1000], dtype=float, name='probs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PosixPath('/home/sherry/.modelci/ResNet50/pytorch-onnx/2.onnx')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# get ONNX model saved path\n",
    "onnx_path = retrieved_models[1].saved_path\n",
    "onnx_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PosixPath('/home/sherry/.modelci/ResNet50/pytorch-trt/2')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# set TensorRT format model save path\n",
    "save_path = generate_path(\n",
    "    model_name='ResNet50', framework=Framework.PYTORCH,engine=Engine.TRT,version=2\n",
    ")\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading ONNX file from path /home/sherry/.modelci/ResNet50/pytorch-onnx/2.onnx...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from modelci.hub.converter import PyTorchConverter\n",
    "TRTConverter.from_onnx(onnx_path, save_path, inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "source": [
    "## 5.Stop the ModelCI Service"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-02 10:36:56.968220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-02 10:36:59,967 - ml-modelci Docker Container Manager - INFO - Container name=gpu-metrics-exporter-52271 stopped.\n",
      "2020-12-02 10:37:01,029 - ml-modelci Docker Container Manager - INFO - Container name=dcgm-exporter-91064 stopped.\n",
      "2020-12-02 10:37:01,560 - ml-modelci Docker Container Manager - INFO - Container name=cadvisor-6052 stopped.\n",
      "2020-12-02 10:37:02,325 - ml-modelci Docker Container Manager - INFO - Container name=mongo-76821 stopped.\n",
      "2020-12-02 10:37:02,448 - modelci backend - INFO - The Uvicorn server with pid=28282 stopped.\n"
     ]
    }
   ],
   "source": [
    "!modelci stop"
   ]
  },
  {
   "source": [
    "Then you can remove all the stoppped docker containers by the following command:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "543bbb7d4cf4\nf54b6218bdfe\n0db5da484143\n4002cbdf701c\n"
     ]
    }
   ],
   "source": [
    "!docker rm $(docker ps -a -q)"
   ]
  },
  {
   "source": [
    "## License\n",
    "\n",
    "```raw\n",
    "Copyright 2020 Nanyang Technological University, Singapore\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}